{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded syllables.py\n"
     ]
    }
   ],
   "source": [
    "from syllables import *\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "from functools import reduce\n",
    "import string\n",
    "import random\n",
    "import shutil\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, XLNetTokenizer, XLNetLMHeadModel\n",
    "from nltk.corpus import cmudict\n",
    "import torch\n",
    "\n",
    "cmu_save = cmudict.entries()\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "xlnet_model = XLNetLMHeadModel.from_pretrained(\"xlnet-base-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Top-k most frequent rhymes\n",
    "RHYME_K = 50                          \n",
    "# for top-k sampling of tokens from language models\n",
    "SAMPLE_K = 40                         \n",
    "# How many times to try a line\n",
    "NUM_TRIES = 6                         \n",
    "### Always pick the best scoring line?\n",
    "GREEDY_PICK_LINE = False\n",
    "### temperature for picking different possible options for lines. Set to 1 to be most permissive. \n",
    "### Set closer to zero to be more conservative and prefer the best scoring line more.\n",
    "PICK_LINE_TEMPERATURE = 0.1\n",
    "### Setting this too high can cause memory problems\n",
    "MAX_CONTEXT_LENGTH = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### These are legit letters\n",
    "STR_LETTERS = set(string.ascii_letters + string.digits)\n",
    "\n",
    "### Is a string a word?\n",
    "def is_word(str):\n",
    "  str_set = set(str)\n",
    "  return len(str) > 0 and str_set.issubset(STR_LETTERS)\n",
    "\n",
    "### Is a letter a vowel?\n",
    "def is_vowel(letter):\n",
    "  return letter in ['a', 'e', 'i', 'o', 'u', 'y']\n",
    "\n",
    "### Is a letter a consonant?\n",
    "def is_consonant(letter):\n",
    "  return not is_vowel(letter)\n",
    "\n",
    "### Is a phoneme a vowel sound?\n",
    "### Pass in a phoneme (get this from Phonetic.phones_list)\n",
    "def is_vowel_sound(phoneme):\n",
    "  return is_vowel(phoneme[0])# and (is_vowel(phoneme[-1]) or phoneme[-1] in ['h', 'x', 'y'])\n",
    "\n",
    "### Is a phoneme a consonant sound?\n",
    "### Pass in a phoneme (get this from Phonetic.phones_list)\n",
    "def is_consonant_sound(phoneme):\n",
    "  return not is_vowel_sound(phoneme)\n",
    "\n",
    "### Return the number of vowel phonemes in a phoneneme list.\n",
    "### Pass in a list of phonemes (get this from Phonetic.phones_list)\n",
    "def num_vowel_phones(phone_list):\n",
    "  count = 0\n",
    "  for ph in phone_list:\n",
    "    if is_vowel(ph[0]):\n",
    "      count = count + 1\n",
    "  return count\n",
    "\n",
    "### For whatever reason, the first call to phonemize crashes because the API call fails.\n",
    "### This calls phonemize() once with a burner word just to get it out of the system\n",
    "def test_phonemize():\n",
    "  word = 'foobar'\n",
    "  try:\n",
    "    festival = phonemize(word, separator=Separator(phone='.', syllable='|', word=' ')).strip()\n",
    "  except:\n",
    "    pass\n",
    "  try:\n",
    "    espeak = phonemize(word, backend='espeak', with_stress=True, separator=Separator(phone='.', syllable='', word=' ')).strip()\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "### Return the indicies of a character (ch) in a string (s)\n",
    "def find_char_indexes(s, ch):\n",
    "    return [i for i, ltr in enumerate(s) if ltr == ch]\n",
    "\n",
    "### Gets the phonemize API going\n",
    "test_phonemize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: phonemizer in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (3.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from phonemizer) (1.3.1)\n",
      "Requirement already satisfied: segments in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from phonemizer) (2.2.1)\n",
      "Requirement already satisfied: attrs>=18.1 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from phonemizer) (22.1.0)\n",
      "Requirement already satisfied: dlinfo in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from phonemizer) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from phonemizer) (4.4.0)\n",
      "Requirement already satisfied: clldutils>=1.7.3 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from segments->phonemizer) (3.19.0)\n",
      "Requirement already satisfied: regex in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from segments->phonemizer) (2023.6.3)\n",
      "Requirement already satisfied: csvw>=1.5.6 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from segments->phonemizer) (3.1.3)\n",
      "Requirement already satisfied: pylatexenc in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from clldutils>=1.7.3->segments->phonemizer) (2.10)\n",
      "Requirement already satisfied: markdown in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from clldutils>=1.7.3->segments->phonemizer) (3.4.1)\n",
      "Requirement already satisfied: markupsafe in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from clldutils>=1.7.3->segments->phonemizer) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from clldutils>=1.7.3->segments->phonemizer) (2.8.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from clldutils>=1.7.3->segments->phonemizer) (4.9.3)\n",
      "Requirement already satisfied: colorlog in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from clldutils>=1.7.3->segments->phonemizer) (6.7.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from clldutils>=1.7.3->segments->phonemizer) (0.9.0)\n",
      "Requirement already satisfied: rdflib in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from csvw>=1.5.6->segments->phonemizer) (6.3.2)\n",
      "Requirement already satisfied: language-tags in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from csvw>=1.5.6->segments->phonemizer) (1.2.0)\n",
      "Requirement already satisfied: babel in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from csvw>=1.5.6->segments->phonemizer) (2.11.0)\n",
      "Requirement already satisfied: requests in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from csvw>=1.5.6->segments->phonemizer) (2.28.1)\n",
      "Requirement already satisfied: rfc3986<2 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from csvw>=1.5.6->segments->phonemizer) (1.5.0)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from csvw>=1.5.6->segments->phonemizer) (4.17.3)\n",
      "Requirement already satisfied: isodate in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from csvw>=1.5.6->segments->phonemizer) (0.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from csvw>=1.5.6->segments->phonemizer) (0.4.6)\n",
      "Requirement already satisfied: uritemplate>=3.0.0 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from csvw>=1.5.6->segments->phonemizer) (4.1.1)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from babel->csvw>=1.5.6->segments->phonemizer) (2022.6)\n",
      "Requirement already satisfied: six in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from isodate->csvw>=1.5.6->segments->phonemizer) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.19.2)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from rdflib->csvw>=1.5.6->segments->phonemizer) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\akash\\appdata\\roaming\\python\\python310\\site-packages (from requests->csvw>=1.5.6->segments->phonemizer) (1.26.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install phonemizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phonemizer.phonemize import phonemize\n",
    "from phonemizer.separator import Separator\n",
    "\n",
    "### Phonetic class\n",
    "### word: orignal word\n",
    "class Phonetic:\n",
    "    def __init__(self, word):\n",
    "        global PHONE_CACHE\n",
    "        self.word = word  # Remember the word\n",
    "        festival = None  # festival results\n",
    "        espeak = None  # espeak results\n",
    "        # If the word is in cache, use those results\n",
    "        if word in PHONE_CACHE:\n",
    "            festival, espeak = PHONE_CACHE[word]\n",
    "        else:\n",
    "            # API calls\n",
    "            festival = phonemize(\n",
    "                word, separator=Separator(phone=\".\", syllable=\"|\", word=\" \")\n",
    "            ).strip()\n",
    "            espeak = phonemize(\n",
    "                word,\n",
    "                backend=\"espeak\",\n",
    "                with_stress=True,\n",
    "                separator=Separator(phone=\".\", syllable=\"\", word=\" \"),\n",
    "            ).strip()\n",
    "            # Store the results\n",
    "            PHONE_CACHE[word] = (festival, espeak)\n",
    "        # List of syllables. Each syllable is a list of phones\n",
    "        self.syllables_with_phones = [\n",
    "            syl[:-1].split(\".\") for syl in festival.split(\"|\")[:-1]\n",
    "        ]\n",
    "        # Just the syllables in raw form\n",
    "        self.syllables = festival.replace(\".\", \"\")\n",
    "        # Just the syllables in list form\n",
    "        self.syllables_list = self.syllables.split(\"|\")[:-1]\n",
    "        # Just the phones in raw form\n",
    "        self.phones = festival.replace(\"|\", \"\")\n",
    "        # Just the phones in list form\n",
    "        self.phones_list = self.phones.split(\".\")[:-1]\n",
    "        self.major_stress = 0  # The major stresses phone (index)\n",
    "        self.minor_stresses = []  # List of minor stressed phones (list of indices)\n",
    "        # Compute the major stress\n",
    "        major_stress_char_idxs = find_char_indexes(espeak, \"ˈ\")\n",
    "        if len(major_stress_char_idxs) > 0:\n",
    "            stress_idx = espeak[: major_stress_char_idxs[0]].count(\".\")\n",
    "            if stress_idx < len(self.phones_list):\n",
    "                self.major_stress = stress_idx\n",
    "            else:\n",
    "                # Find the next earliest vowel phone\n",
    "                for i in range(len(self.phones_list)):\n",
    "                    if is_vowel_sound(self.phones_list[len(self.phones_list) - i - 1]):\n",
    "                        self.major_stress = len(self.phones_list) - i - 1\n",
    "                        break\n",
    "        # compute the minor stresses\n",
    "        minor_stress_char_idxs = find_char_indexes(espeak, \"ˌ\")\n",
    "        if len(minor_stress_char_idxs) > 0:\n",
    "            for char_idx in minor_stress_char_idxs:\n",
    "                stress_idx = espeak[:char_idx].count(\".\")\n",
    "                if stress_idx < len(self.phones_list):\n",
    "                    self.minor_stresses.append(stress_idx)\n",
    "                else:\n",
    "                    # Find the next earliest vowel phone\n",
    "                    for i in range(len(self.phones_list)):\n",
    "                        if is_vowel_sound(\n",
    "                            self.phones_list[len(self.phones_list) - i - 1]\n",
    "                        ):\n",
    "                            self.minor_stresses.append(len(self.phones_list) - i - 1)\n",
    "                            break\n",
    "            # all stressed phones (list of indices)\n",
    "        self.all_stresses = sorted([self.major_stress] + self.minor_stresses[:])\n",
    "\n",
    "    def num_phones(self):\n",
    "        return len(self.phones_list)\n",
    "\n",
    "    def num_syllables(self):\n",
    "        return len(self.syllables_list)\n",
    "\n",
    "    def get_num_vowels(self):\n",
    "        return num_vowel_phones(self.phones_list)\n",
    "\n",
    "    def get_nth_vowel_phone(self, n=0):\n",
    "        count = -1\n",
    "        for i, ph in enumerate(self.phones_list):\n",
    "            if is_vowel_sound(ph):\n",
    "                count = count + 1\n",
    "            if count == n:\n",
    "                return ph, i\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_syllable_of_nth_phone(self, n):\n",
    "        count = -1\n",
    "        for i, syl in enumerate(self.syllables_list):\n",
    "            for ph in syl:\n",
    "                count = count + 1\n",
    "                if count == n:\n",
    "                    return i\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Return true if two words are perfect ryles of each other\n",
    "def perfect_rhyme(word1, word2):\n",
    "  phonetic1 = Phonetic(word1)\n",
    "  phonetic2 = Phonetic(word2)\n",
    "  stress1 = phonetic1.all_stresses[-1]\n",
    "  stress2 = phonetic2.all_stresses[-1]\n",
    "  if phonetic1.num_phones() - stress1 != phonetic2.num_phones() - stress2:\n",
    "    return False\n",
    "  for i in range(phonetic1.num_phones() - stress1):\n",
    "    phone1 = phonetic1.phones_list[i + stress1]\n",
    "    phone2 = phonetic2.phones_list[i + stress2]\n",
    "    if phone1 != phone2:\n",
    "      return False\n",
    "  return True\n",
    "\n",
    "### Let's pretend that these phones are the same\n",
    "### (In addition all vowel phones that start with the same letter will be considered the same)\n",
    "NEAR_SETS = [['er', 'r'], \n",
    "             #['ih', 'eh'],\n",
    "             ['eh', 'ah'],\n",
    "             ['er', 'ax'],\n",
    "             ['ae', 'ey'],\n",
    "             ['t', 'f'],\n",
    "             ['b', 'k'],\n",
    "             ['p', 'z', 'th'],\n",
    "             ['s', 'st', 'sk'],\n",
    "             ['nt', 'ns'],\n",
    "             ['n', 'ng']\n",
    "             ]\n",
    "\n",
    "### These phonemes start with the same letter but should not be considered eqivalent\n",
    "FAR_SETS =[['aw', 'ay', 'ax'],\n",
    "           ['ax', 'ao']]\n",
    "\n",
    "### Determine if phonemes are a near match\n",
    "def near_match(phone1, phone2):\n",
    "  # Safety check\n",
    "  if (phone1 is None) or (phone2 is None) or (len(phone1) == 0 and len(phone2) > 0) or (len(phone2) == 0 and len(phone1) > 0):\n",
    "    return False\n",
    "  if phone1 == phone2:\n",
    "    # Phones are the same\n",
    "    return True\n",
    "  elif is_vowel_sound(phone1) and is_vowel_sound(phone2) and phone1[0] == phone2[0]:\n",
    "    # Vowel sounds start with the same letter\n",
    "    # Check that they are not in the same far set\n",
    "    for fs in FAR_SETS:\n",
    "      if phone1 in fs and phone2 in fs:\n",
    "        return False\n",
    "    return True\n",
    "  else:\n",
    "    # Check to see if the pair of phones are in the same near_set\n",
    "    for ns in NEAR_SETS:\n",
    "      if phone1 in ns and phone2 in ns:\n",
    "        return True\n",
    "  return False\n",
    "\n",
    "### Check if every phone in list 1 is a near match to corresponding phone in list 2\n",
    "def near_matches(phone_list1, phone_list2):\n",
    "  if len(phone_list1) != len(phone_list2):\n",
    "    return False\n",
    "  else:\n",
    "    for i in range(len(phone_list1)):\n",
    "      if not near_match(phone_list1[i], phone_list2[i]):\n",
    "        return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### If you turn this on, it will print information about the phoneme analysis being conducted\n",
    "### every time near_rhyme() is called. Not recommended\n",
    "VERBOSE = False\n",
    "\n",
    "\n",
    "### Verbose print allows for debug printing to be turned off\n",
    "def vprint(*args):\n",
    "    if VERBOSE:\n",
    "        print(\" \".join([str(a) for a in args]))\n",
    "\n",
    "\n",
    "### Determine if word1 and word2 are near rhymes\n",
    "### if last_consonant is False, we won't check for near matches of the last consonant\n",
    "def near_rhyme(word1, word2, last_consonant=True):\n",
    "    if perfect_rhyme(word1, word2):\n",
    "        return True\n",
    "    phonetic1 = Phonetic(word1)\n",
    "    phonetic2 = Phonetic(word2)\n",
    "    stress1 = phonetic1.all_stresses[-1]  # The last stressed phone\n",
    "    stress2 = phonetic2.all_stresses[-1]  # The last stressed phone\n",
    "    vprint(phonetic1.syllables_with_phones, phonetic1.all_stresses)\n",
    "    vprint(phonetic2.syllables_with_phones, phonetic2.all_stresses)\n",
    "\n",
    "    # Word = a v x w c\n",
    "    # a = prefix (not important)\n",
    "    # v = last stressed vowel\n",
    "    # x = any number of phones between v and w\n",
    "    # w = last vowel\n",
    "    # c = consonant after last vowel\n",
    "\n",
    "    # Last stressed vowel (v)\n",
    "    v1_index = stress1\n",
    "    v2_index = stress2\n",
    "    v1 = phonetic1.phones_list[v1_index]\n",
    "    v2 = phonetic2.phones_list[v2_index]\n",
    "    vprint(\"v:\", v1, v1_index, v2, v2_index)\n",
    "\n",
    "    # Last vowel (w)\n",
    "    w1, w1_index = phonetic1.get_nth_vowel_phone(phonetic1.get_num_vowels() - 1)\n",
    "    w2, w2_index = phonetic2.get_nth_vowel_phone(phonetic2.get_num_vowels() - 1)\n",
    "    vprint(\"w:\", w1, w1_index, w2, w2_index)\n",
    "\n",
    "    # Consonants after last vowel (c)\n",
    "    c1_index = w1_index + 1\n",
    "    c1 = \"\".join(phonetic1.phones_list[c1_index : phonetic1.num_phones()])\n",
    "    c2_index = w2_index + 1\n",
    "    c2 = \"\".join(phonetic2.phones_list[c2_index : phonetic2.num_phones()])\n",
    "    vprint(\"c:\", c1, c1_index, c2, c2_index)\n",
    "\n",
    "    # phones between v and w (x)\n",
    "    x1 = phonetic1.phones_list[v1_index + 1 : w1_index]\n",
    "    x2 = phonetic2.phones_list[v2_index + 1 : w2_index]\n",
    "    vprint(\"x:\", x1, x2)\n",
    "\n",
    "    # p = first phone in x\n",
    "    # q = last phone in x\n",
    "    p1 = None\n",
    "    q1 = None\n",
    "    p2 = None\n",
    "    q2 = None\n",
    "    if len(x1) > 0:\n",
    "        p1 = x1[0]\n",
    "        q1 = x1[-1]\n",
    "    if len(x2) > 0:\n",
    "        p2 = x2[0]\n",
    "        q2 = x2[-1]\n",
    "    vprint(\"p,q:\", p1, q1, p2, q2)\n",
    "\n",
    "    if not near_match(w1, w2):\n",
    "        vprint(\"w fail\")\n",
    "        return False\n",
    "    elif not near_match(v1, v2):\n",
    "        vprint(\"v fail\")\n",
    "        return False\n",
    "    elif False and len(c1) != len(c2) and (len(c1) > 1 or len(c2) > 1):\n",
    "        vprint(\"c not same length - fail\")\n",
    "        return False\n",
    "    elif last_consonant and not near_match(c1, c2):\n",
    "        vprint(\"cs dont match - fail\")\n",
    "        return False\n",
    "    elif len(x1) == 0 and len(x2) == 0:\n",
    "        vprint(\"no x - match\")\n",
    "        return True\n",
    "    elif len(x1) == 1 and len(x2) == 1 and near_match(x1[0], x2[0]):\n",
    "        vprint(\"single x - match\")\n",
    "        return True\n",
    "    elif len(x1) > 0 and len(x2) > 0 and num_vowel_phones(x1) != num_vowel_phones(x2):\n",
    "        vprint(\"num vowel phones in x - fail\")\n",
    "        return False\n",
    "    elif near_match(p1, p2) and near_match(q1, q2):\n",
    "        vprint(\"ps or qs - match\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "NEAR_RHYME_PATH = \"data/near_rhymes20000\"\n",
    "PHONE_CACHE_PATH = \"data/phone_cache\"\n",
    "NEAR_RHYME_DICT_FILENAME = \"data/near_rhymes20000_dict\"\n",
    "PHONE_CACHE_FILENAME = \"data/phone_cache_dict\"\n",
    "\n",
    "if not os.path.exists(NEAR_RHYME_PATH):\n",
    "    url_near_rhymes = \"https://www.dropbox.com/s/8a800ivlp0uknic/near_rhymes20000.zip?dl=1\"\n",
    "    urllib.request.urlretrieve(url_near_rhymes, \"near_rhymes20000.zip\")\n",
    "    with zipfile.ZipFile(\"near_rhymes20000.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(NEAR_RHYME_PATH)\n",
    "    os.remove(\"near_rhymes20000.zip\")\n",
    "\n",
    "if not os.path.exists(PHONE_CACHE_PATH):\n",
    "    url_phone_cache = \"https://www.dropbox.com/s/i57hvmnlint7wj3/phone_cache.zip?dl=1\"\n",
    "    urllib.request.urlretrieve(url_phone_cache, \"phone_cache.zip\")\n",
    "    with zipfile.ZipFile(\"phone_cache.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(PHONE_CACHE_PATH)\n",
    "    os.remove(\"phone_cache.zip\")\n",
    "\n",
    "if not os.path.exists(NEAR_RHYME_PATH):\n",
    "    shutil.copyfile(NEAR_RHYME_DICT_FILENAME, NEAR_RHYME_PATH)\n",
    "\n",
    "if not os.path.exists(PHONE_CACHE_PATH):\n",
    "    shutil.copyfile(PHONE_CACHE_FILENAME, PHONE_CACHE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the phone cache from disk\n",
    "def load_phone_cache(filename):\n",
    "    cache = {}\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            split_line = line.split(\"\\t\")\n",
    "            if len(split_line) >= 3:\n",
    "                word, festival, espeak = split_line\n",
    "                cache[word] = (festival, espeak)\n",
    "\n",
    "        return cache\n",
    "    return cache\n",
    "\n",
    "\n",
    "def load_near_rhyme_dictionary(filename):\n",
    "    rhyme_dict = {}\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split(\"\\t\")\n",
    "            key = line[0].strip()\n",
    "            val = line[1].strip()\n",
    "            if key not in rhyme_dict:\n",
    "                rhyme_dict[key] = []\n",
    "            rhyme_dict[key].append(val)\n",
    "        return rhyme_dict\n",
    "    return rhyme_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(NEAR_RHYME_PATH):\n",
    "    NEAR_RHYME_DICT = load_near_rhyme_dictionary(NEAR_RHYME_PATH + \"/near_rhymes20000\")\n",
    "\n",
    "if os.path.exists(PHONE_CACHE_PATH):\n",
    "    PHONE_CACHE = load_phone_cache(PHONE_CACHE_PATH + \"/phone_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make a dictionary remembering whether words are near rhymes to each other.\n",
    "def make_near_rhyme_dictionary(top_n, filename, rhyme_dict=None):\n",
    "    global VERBOSE\n",
    "    VERBOSE = False  # Turn off debugging prints\n",
    "    near_rhymes = []\n",
    "    # Get top n most frequent words\n",
    "    top = top_n_list(\"en\", top_n, wordlist=\"best\")\n",
    "    for i, w1 in enumerate(top):\n",
    "        for j, w2 in enumerate(top):\n",
    "            if is_word(w1) and is_word(w2) and w1 != w2:\n",
    "                if (\n",
    "                    rhyme_dict is None\n",
    "                    or w1 not in rhyme_dict\n",
    "                    or w2 not in rhyme_dict[w1]\n",
    "                ):\n",
    "                    if near_rhyme(w1, w2):\n",
    "                        print(\n",
    "                            \"MATCH\",\n",
    "                            i,\n",
    "                            j,\n",
    "                            w1,\n",
    "                            w2,\n",
    "                        )\n",
    "                        near_rhymes.append((w1, w2))\n",
    "    if rhyme_dict is not None:\n",
    "        for key in list(rhyme_dict.keys()):\n",
    "            for val in rhyme_dict[key]:\n",
    "                near_rhymes.append((key, val))\n",
    "                near_rhymes.append((val, key))\n",
    "    with open(filename, \"w\") as f:\n",
    "        for w1, w2 in near_rhymes:\n",
    "            f.write(w1 + \"\\t\" + w2 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLNetLMHeadModel(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_loss): Linear(in_features=768, out_features=32000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlnet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Are GPUs available?\n",
    "CUDA_AVAILABLE = torch.cuda.is_available()\n",
    "\n",
    "# Which model is in the GPU (string)\n",
    "MODEL_IN_GPU = None\n",
    "# Which models are we using and what are their names?\n",
    "MODEL_HASH = {\"gpt\": gpt2_model, \"xlnet\": xlnet_model}\n",
    "\n",
    "\n",
    "def _prep_model(model_name):\n",
    "    global MODEL_IN_GPU, MODELS_NOT_IN_GPU\n",
    "    if MODEL_IN_GPU != model_name:\n",
    "        # Unload the model in the gpu (if any)\n",
    "        if MODEL_IN_GPU is not None:\n",
    "            MODEL_HASH[MODEL_IN_GPU].to(\"cpu\")\n",
    "            MODEL_IN_GPU = None\n",
    "        # Load the new model to gpu\n",
    "        if CUDA_AVAILABLE:\n",
    "            print(\"LOADING\", model_name)\n",
    "            MODEL_HASH[model_name].to(\"cuda\")\n",
    "            MODEL_IN_GPU = model_name\n",
    "\n",
    "\n",
    "# For backward compatibility:\n",
    "def prep_gpt():\n",
    "    print(\"Using GPT\")\n",
    "    _prep_model(\"gpt\")\n",
    "\n",
    "\n",
    "def prep_xlnet():\n",
    "    print(\"Using XLNet\")\n",
    "    _prep_model(\"xlnet\")\n",
    "\n",
    "\n",
    "# Decorators!\n",
    "def use_gpt(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        _prep_model(\"gpt\")\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def use_xlnet(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        _prep_model(\"xlnet\")\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This does top-k and top-p sampling from a list of logits. Borrowed from original GPT-2 code.\n",
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### These are punctuation\n",
    "from string import punctuation as PUNCTUATION\n",
    "from string import digits as NUMBERS\n",
    "\n",
    "### Periods are important\n",
    "PERIOD = \".\"\n",
    "BLANK = \" \"\n",
    "\n",
    "\n",
    "### Is this string punctuation?\n",
    "def is_punctuation(s):\n",
    "    return len(set(s).intersection(set(PUNCTUATION))) > 0\n",
    "\n",
    "\n",
    "### Remove punctuation from string\n",
    "def remove_punctuation(s):\n",
    "    return \"\".join(i for i in s if not i in PUNCTUATION)\n",
    "\n",
    "\n",
    "### How many syllables in this string?\n",
    "def get_syllables_for_line(line):\n",
    "    line = \"\".join(list(filter(lambda c: c in STR_LETTERS or c == BLANK, line)))\n",
    "    count = 0\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        word = word.strip()\n",
    "        if len(word) > 0 and is_word(word):\n",
    "            phonetic = Phonetic(word)\n",
    "            count = count + phonetic.num_syllables()\n",
    "    return count\n",
    "\n",
    "\n",
    "### Remove the prefix from the string (s)\n",
    "def remove_prefix(s, prefix):\n",
    "    rest = s[len(prefix) :] if s.startswith(prefix) else s\n",
    "    return rest\n",
    "\n",
    "\n",
    "### The system considers whether to terminate a line after the line is generated.\n",
    "### So punctuation of a line could end up in the next line down.\n",
    "def fix_final_lines_punctuation(lines):\n",
    "    new_lines = []\n",
    "    for i, line in enumerate(lines):\n",
    "        if i > 0 and line[0] in PUNCTUATION:\n",
    "            new_lines[-1] = new_lines[-1] + line[0]\n",
    "            new_lines.append(line[1:].strip())\n",
    "        else:\n",
    "            new_lines.append(line.strip())\n",
    "    return new_lines\n",
    "\n",
    "\n",
    "def fix_final_lines_capitalization(lines):\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        new_line = line[0].upper() + line[1:].lower()\n",
    "        new_lines.append(new_line)\n",
    "    return new_lines\n",
    "\n",
    "\n",
    "### Figure out how to put two lines (strings) together.\n",
    "### If force_break is True, then put a sentence break (period) between the two.\n",
    "### Otherwise, try to figure out if there should be a period between.\n",
    "def merge_lines(l1, l2, force_break=False):\n",
    "    if len(l1) == 0:\n",
    "        return l2\n",
    "    elif len(l2) == 0 and force_break:\n",
    "        return l1 + PERIOD\n",
    "    elif len(l2) == 0:\n",
    "        return l1\n",
    "    elif not is_punctuation(l1[-1]) and force_break:\n",
    "        return l1 + PERIOD + BLANK + l2\n",
    "    else:\n",
    "        return l1 + BLANK + l2\n",
    "\n",
    "\n",
    "### Figure out which xlnet tokens are numbers\n",
    "def xlnet_number_tokens():\n",
    "    nums = []\n",
    "    for i in range(len(xlnet_tokenizer.get_vocab())):\n",
    "        s = xlnet_tokenizer.decode(i)\n",
    "        if (\n",
    "            len(s) > 0 and len(set(s).intersection(set(NUMBERS))) > 0\n",
    "        ):  # s[0] in NUMBERS:\n",
    "            nums.append((i, s))\n",
    "    return nums\n",
    "\n",
    "\n",
    "### Figure out which gpt tokens are numbers\n",
    "def gpt_number_tokens():\n",
    "    nums = []\n",
    "    for i in range(len(gpt2_tokenizer.get_vocab())):\n",
    "        s = gpt2_tokenizer.decode(i)\n",
    "        if (\n",
    "            len(s) > 0 and len(set(s).intersection(set(NUMBERS))) > 0\n",
    "        ):  # s[0] in NUMBERS:\n",
    "            nums.append((i, s))\n",
    "    return nums\n",
    "\n",
    "\n",
    "### Find all the numbers in xlnet and gpt vocabularies\n",
    "XLNET_NUMBER_TOKENS = list(map(lambda x: x[0], xlnet_number_tokens()))\n",
    "GPT_NUMBER_TOKENS = list(map(lambda x: x[0], gpt_number_tokens()))\n",
    "\n",
    "\n",
    "### Print lyrics\n",
    "def pretty_print(lines):\n",
    "    print(\"---------\")\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "    print(\"---------\")\n",
    "\n",
    "\n",
    "EXCLAIMS = [\"oh!\", \"ah!\", \"yeah!\"]\n",
    "\n",
    "\n",
    "## If we don't have enough syllables, add some ohs ahs and yeahs\n",
    "def add_filler(line, count, start):\n",
    "    prefix = line[0:start]\n",
    "    suffix = line[start:]\n",
    "    filler = []\n",
    "    for i in range(count):\n",
    "        filler.append(random.choice(EXCLAIMS))\n",
    "    return prefix + BLANK + BLANK.join(filler) + BLANK + suffix\n",
    "\n",
    "\n",
    "## We get weird punctuation. Remove it\n",
    "def remove_extra_punctuation(line):\n",
    "    idx = len(line)\n",
    "    for i in range(1, len(line)):\n",
    "        pos = len(line) - i\n",
    "        if line[pos] in PUNCTUATION:\n",
    "            idx = pos\n",
    "        else:\n",
    "            break\n",
    "    return line[0:idx]\n",
    "\n",
    "\n",
    "### Merge two dictionaries.\n",
    "### The dictionaries should contain lists as values.\n",
    "def merge_dicts(dict1, dict2):\n",
    "    if dict1 is None or dict2 is None:\n",
    "        return {}\n",
    "    new_dict = copy.deepcopy(dict1)\n",
    "    for key in list(dict2.keys()):\n",
    "        val_list = dict2[key]\n",
    "        if key not in new_dict:\n",
    "            new_dict[key] = []\n",
    "        new_dict[key] += val_list\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "### Count how many times each word occurs in a line.\n",
    "def word_counts(line):\n",
    "    counts = {}\n",
    "    new_line = \"\".join(list(filter(lambda c: c not in PUNCTUATION, line)))\n",
    "    for word in new_line.split():\n",
    "        if word not in counts:\n",
    "            counts[word] = 0\n",
    "        counts[word] += 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "### Get rid of any lines that uses a word more than once\n",
    "def filter_lines(lines):\n",
    "    return list(filter(lambda line: max(word_counts(line).values()) <= 1, lines))\n",
    "\n",
    "\n",
    "### Make sure our lines don't get too long\n",
    "def crop_line(line):\n",
    "    enc = gpt2_tokenizer.encode(line)\n",
    "    if len(enc) > MAX_CONTEXT_LENGTH:\n",
    "        enc = enc[len(enc) - MAX_CONTEXT_LENGTH :]\n",
    "    dec = gpt2_tokenizer.decode(enc)\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def repeat_fn(line, all_lines, line_number, spec, args):\n",
    "    target_syllables = args[0]\n",
    "    ref_line = all_lines[line_number]\n",
    "    ref_line = \"\".join(c for c in ref_line if not c in PUNCTUATION)\n",
    "    if target_syllables == \"all\":\n",
    "        return ref_line, all_lines, line_number, spec\n",
    "    else:\n",
    "        ref_line_words = ref_line.split()\n",
    "        syllable_count = 0\n",
    "        picked_words = []\n",
    "        for word in reversed(ref_line_words):\n",
    "            num_syllables = get_syllables_for_line(word)\n",
    "            syllable_count = syllable_count + num_syllables\n",
    "            picked_words.append(word)\n",
    "            if syllable_count >= target_syllables:\n",
    "                break\n",
    "        return BLANK.join(reversed(picked_words)), all_lines, line_number, spec\n",
    "\n",
    "\n",
    "def frepeat_fn(line, all_lines, line_number, spec, args):\n",
    "    target_syllables = args[0]\n",
    "    ref_line = all_lines[line_number]\n",
    "    ref_line = \"\".join(c for c in ref_line if not c in PUNCTUATION)\n",
    "    if target_syllables == \"all\":\n",
    "        return ref_line, all_lines, line_number, spec\n",
    "    else:\n",
    "        ref_line_words = ref_line.split()\n",
    "        syllable_count = 0\n",
    "        picked_words = []\n",
    "        for word in ref_line_words:\n",
    "            num_syllables = get_syllables_for_line(word)\n",
    "            syllable_count = syllable_count + num_syllables\n",
    "            picked_words.append(word)\n",
    "            if syllable_count >= target_syllables:\n",
    "                break\n",
    "        return BLANK.join(picked_words), all_lines, line_number, spec\n",
    "\n",
    "\n",
    "def copy_fn(line, all_lines, line_number, spec, args):\n",
    "    new_spec = {}\n",
    "    line_to_copy = args[0]\n",
    "    copied_line = all_lines[line_to_copy]\n",
    "    new_all_lines = (\n",
    "        all_lines[0 : line_number + 1] + [copied_line] + all_lines[line_number + 1 :]\n",
    "    )\n",
    "    for key in list(spec.keys()):\n",
    "        val = spec[key]\n",
    "        if key > line_number:\n",
    "            new_spec[key + 1] = val\n",
    "        else:\n",
    "            new_spec[key] = val\n",
    "    return \"\", new_all_lines, line_number, new_spec\n",
    "\n",
    "\n",
    "PARSE_FUNCTIONS = {\"repeat\": repeat_fn, \"copy\": copy_fn, \"frepeat\": frepeat_fn}\n",
    "\n",
    "\n",
    "def parse(line, all_lines, line_number, spec):\n",
    "    done = False\n",
    "    while not done:\n",
    "        match = re.search(r\"\\{([\\w]+)[ ]*([\\w, ]*)\\}\", line)\n",
    "        if match is None:\n",
    "            done = True\n",
    "        else:\n",
    "            func = match.groups()[0]\n",
    "            args = eval(match.groups()[1])\n",
    "            if not isinstance(args, tuple):\n",
    "                args = tuple([args])\n",
    "            pre = line[0 : match.start()]\n",
    "            mid, all_lines, line_number, spec = PARSE_FUNCTIONS[func](\n",
    "                line, all_lines, line_number, spec, args\n",
    "            )\n",
    "            post = line[match.end() :]\n",
    "            line = pre + mid + post\n",
    "    return line, all_lines, line_number, spec\n",
    "\n",
    "\n",
    "### Add post-processing information to each line\n",
    "def post_process_lines(lines, spec):\n",
    "    new_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        if i in spec:\n",
    "            pre, post = spec[i]\n",
    "            if pre is not None:\n",
    "                pre, lines, i, spec = (\n",
    "                    parse(pre, lines, i, spec) if pre is not None else \"\"\n",
    "                )\n",
    "                line = lines[i]\n",
    "            else:\n",
    "                pre = \"\"\n",
    "            if post is not None:\n",
    "                post, lines, i, spec = (\n",
    "                    parse(post, lines, i, spec) if post is not None else \"\"\n",
    "                )\n",
    "                line = lines[i]\n",
    "            else:\n",
    "                post = \"\"\n",
    "            new_lines.append(pre + line + post)\n",
    "        else:\n",
    "            new_lines.append(line)\n",
    "        i = i + 1\n",
    "    return new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "### Pick the word from the words list that is most similar to the context according to BERT\n",
    "def pick_similar(context, words, history = []): \n",
    "    words = words[:]\n",
    "    token_hash = {}\n",
    "    for word in words:\n",
    "        token_hash[tuple(gpt2_tokenizer.encode(word))] = None\n",
    "    \n",
    "    #prep_gpt()\n",
    "    context_tokens = gpt2_tokenizer.encode(context) \n",
    "    prompt = torch.tensor([context_tokens]) # context put into the right shape\n",
    "    prompt = prompt.to('cuda') if CUDA_AVAILABLE else prompt\n",
    "    past = None \n",
    "    beams = []\n",
    "    for i in range(10):\n",
    "        current_beam = []\n",
    "        for j in range(20):\n",
    "            # Generate\n",
    "            output, new_past = gpt2_model(prompt, past_key_values=past)\n",
    "            # Top k filter: there are k real numbers and the rest are -inf\n",
    "            logits = output[0][0][:]\n",
    "            tokens = torch.multinomial(F.softmax(logits), 10)\n",
    "            #token = tokens[0]\n",
    "            for tok in tokens.tolist():\n",
    "                word = gpt2_tokenizer.decode(tok)\n",
    "                if not is_punctuation(word):\n",
    "                    current_beam.append((tok, F.softmax(logits)))\n",
    "                    prompt = torch.tensor([tok]).unsqueeze(0)\n",
    "                    prompt = prompt.to('cuda')\n",
    "                    past = new_past\n",
    "                    break\n",
    "            #if token == 13:\n",
    "            #  break\n",
    "            #else:\n",
    "            #  current_beam.append((token, logits))\n",
    "            #  prompt = torch.tensor([token]).unsqueeze(0)\n",
    "            #  prompt = prompt.to('cuda')\n",
    "            #  past = new_past\n",
    "        beams.append(current_beam)\n",
    "        # ASSERT: we have 10 beams of 20 tokens or less\n",
    "        '''\n",
    "        for b in beams:\n",
    "        x = []\n",
    "        for tok, ls in b:\n",
    "            x.append(tok)\n",
    "        print('---')\n",
    "        print(GPT_TOKENIZER.decode(x))\n",
    "        '''\n",
    "    for key in list(token_hash.keys()):\n",
    "        sum = 0\n",
    "        for beam in beams:\n",
    "            for i in range(len(beam)):\n",
    "                for j, tok in enumerate(key):\n",
    "                    if i+j < len(beam):\n",
    "                        logits = beam[i+j][1]\n",
    "                        sum = sum + logits[tok]\n",
    "                if len(key) > 1:\n",
    "                    sum = sum / len(key)\n",
    "            #if len(beam) > 1:\n",
    "            #  sum = sum / len(beam)\n",
    "        if token_hash[key] is None:\n",
    "            token_hash[key] = sum\n",
    "        else:\n",
    "            token_hash[key] = max(token_hash[key], sum)\n",
    "    # ASSERT: Token_hash populated with good values\n",
    "    vals = torch.stack(list(token_hash.values()))\n",
    "    #soft = F.softmax(vals)\n",
    "    #mask = soft > 0.0\n",
    "    #num_nonzero = torch.sum(mask.int())\n",
    "    vals = vals + -vals.min()\n",
    "    #vals = F.softmax(vals)\n",
    "    #vals = -vals\n",
    "    #topk = torch.multinomial(soft, min(10, len(words), num_nonzero.item()), replacement=False).tolist()\n",
    "    final_pick = None\n",
    "    if vals.sum().item() > 0:\n",
    "        topk = torch.multinomial(vals, vals.size()[0], replacement=False).tolist()\n",
    "        print(\"Picking from:\", list(map(lambda x: words[x], topk)), \"given history\", history)\n",
    "        #pdb.set_trace()\n",
    "        for idx in topk:\n",
    "            if words[idx] not in history:\n",
    "                final_pick = words[idx]\n",
    "                break\n",
    "    if final_pick is None and len(words) >= 1:\n",
    "        final_pick = random.choice(words)\n",
    "    if final_pick is None:\n",
    "        # Uh oh we didn't find anything, probably because all the hits were in history\n",
    "        sorted_words = sorted(words, key=lambda w: token_hash[tuple(gpt2_tokenizer.encode(w))], reverse=True)\n",
    "        print(\"Second attempt\", sorted_words, \"history\", history)\n",
    "        final_pick = None\n",
    "        for w in sorted_words:\n",
    "            if w not in history:\n",
    "                final_pick = w\n",
    "                break\n",
    "        if final_pick is None:\n",
    "            weights = list(map(lambda w: -token_hash[tuple(gpt2_tokenizer.encode(w))], sorted_words))\n",
    "            print(\"Third attempt\", sorted_words, \"history\", history)\n",
    "            final_pick = random.choices(sorted_words, weights)[0]\n",
    "    print(\"Picking\", final_pick)\n",
    "    return final_pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordfreq import word_frequency, top_n_list\n",
    "import pronouncing\n",
    "\n",
    "END_NO_WORDS = [\n",
    "    \"and\",\n",
    "    \"to\",\n",
    "    \"the\",\n",
    "    \"a\",\n",
    "    \"with\",\n",
    "    \"an\",\n",
    "    \"of\",\n",
    "    \"as\",\n",
    "    \"if\",\n",
    "    \"is\",\n",
    "    \"for\",\n",
    "    \"or\",\n",
    "    \"nor\",\n",
    "    \"in\",\n",
    "    \"we\",\n",
    "    \"my\",\n",
    "    \"from\",\n",
    "    \"that\",\n",
    "    \"your\",\n",
    "]\n",
    "\n",
    "NO_RHYME_WORDS = [\n",
    "    \"francoise\",\n",
    "    \"l'enfant\",\n",
    "    \"un\",\n",
    "    \"vanhove\",\n",
    "    \"suhud\",\n",
    "    \"re\",\n",
    "    \"le\",\n",
    "    \"tao\",\n",
    "    \"mao\",\n",
    "    \"lao\",\n",
    "    \"petr\",\n",
    "    \"chas\",\n",
    "    \"rao\",\n",
    "    \"raby\",\n",
    "    \"rabey\",\n",
    "    \"ia\",\n",
    "    \"co\",\n",
    "    \"uk\",\n",
    "    \"a\",\n",
    "    \"i\",\n",
    "    \"the\",\n",
    "    \"nba\",\n",
    "    \"dna\",\n",
    "    \"fda\",\n",
    "    \"gta\",\n",
    "    \"c'est\",\n",
    "    \"les\",\n",
    "    \"tor\",\n",
    "    \"dvd\",\n",
    "    \"labov\",\n",
    "    \"stumm\",\n",
    "    \"yu\",\n",
    "    \"du\",\n",
    "    \"mon\",\n",
    "    \"aka\",\n",
    "    \"de\",\n",
    "    \"ne\",\n",
    "    \"que\",\n",
    "    \"ga\",\n",
    "    \"si\",\n",
    "    \"ap\",\n",
    "    \"ta\",\n",
    "    \"und\",\n",
    "    \"des\",\n",
    "    \"wa\",\n",
    "    \"ka\",\n",
    "    \"ra\",\n",
    "    \"ba\",\n",
    "    \"da\",\n",
    "    \"aa\",\n",
    "    \"ca\",\n",
    "    \"va\",\n",
    "    \"ja\",\n",
    "    \"sa\",\n",
    "    \"fa\",\n",
    "    \"ou\",\n",
    "    \"eu\",\n",
    "    \"tu\",\n",
    "    \"su\",\n",
    "    \"fu\",\n",
    "    \"wu\",\n",
    "    \"dui\",\n",
    "    \"der\",\n",
    "    \"ib\",\n",
    "    \"something\",\n",
    "    \"jesus\",\n",
    "    \"twentysomething\",\n",
    "    \"schaab\",\n",
    "    \"soo\",\n",
    "    \"grier\",\n",
    "    \"guangdong\",\n",
    "] + END_NO_WORDS\n",
    "\n",
    "RHYME_VOCAB_TOP_N = 50000\n",
    "\n",
    "\n",
    "### Remove some words from rhyme dictionary\n",
    "def filter_rhyme(word):\n",
    "    return (\n",
    "        (PERIOD not in word)\n",
    "        and (\"-\" not in word)\n",
    "        and (len(word) > 1 or word == \"a\" or word == \"I\" or word == \"i\")\n",
    "        and (word.lower() not in NO_RHYME_WORDS)\n",
    "        and (word.lower() in top_n_list(\"en\", RHYME_VOCAB_TOP_N))\n",
    "    )\n",
    "\n",
    "\n",
    "### Uniformly pick amongst top k most frequent perfect rhymes\n",
    "def pick_perfect_rhyme(word, context=None, history=[]):\n",
    "    # Remove unwanted letters\n",
    "    word = \"\".join(list(filter(lambda c: c in STR_LETTERS, word)))\n",
    "    # Get rhymes\n",
    "    rhymes = pronouncing.rhymes(word)\n",
    "    # Remove unwanted words\n",
    "    rhymes = list(filter(lambda w: filter_rhyme(w), rhymes))\n",
    "    # If there aren't any rhymes, return the current word\n",
    "    if len(rhymes) == 0:\n",
    "        return word\n",
    "    else:\n",
    "        # Make sure k is smaller than total number of rhymes available\n",
    "        k = min(RHYME_K, len(rhymes))\n",
    "        # Get word frequency of rhymes\n",
    "        probs = list(map(lambda r: word_frequency(r, \"en\"), rhymes))\n",
    "        probs_tensor = torch.tensor(probs)\n",
    "        # Get top k\n",
    "        vals, idxs = torch.topk(probs_tensor, k)\n",
    "        if context is not None and len(context) > 0:\n",
    "            candidates = [rhymes[x] for x in idxs.tolist()]\n",
    "            pick = pick_similar(context, candidates, history)\n",
    "            return pick\n",
    "        else:\n",
    "            # Pick uniformly\n",
    "            r = random.randint(0, k - 1)\n",
    "            return rhymes[idxs[r].item()]\n",
    "\n",
    "\n",
    "### Pick best near rhyme from the near rhyme dictionary\n",
    "def pick_near_rhyme(word, context=None, history=[]):\n",
    "    global NEAR_RHYME_DICT\n",
    "    if NEAR_RHYME_DICT is None:\n",
    "        NEAR_RHYME_DICT = load_near_rhyme_dictionary(NEAR_RHYME_PATH)\n",
    "    # Remove unwanted letters\n",
    "    word = \"\".join(list(filter(lambda c: c in STR_LETTERS, word)))\n",
    "    # Get rhymes\n",
    "    near_rhymes = []\n",
    "    # rhymes = []\n",
    "    if word in NEAR_RHYME_DICT:\n",
    "        near_rhymes = NEAR_RHYME_DICT[word]\n",
    "    if len(near_rhymes) > 0:\n",
    "        rhymes = near_rhymes\n",
    "    # else:\n",
    "    #  rhymes = pronouncing.rhymes(word)\n",
    "    rhymes = list(set(near_rhymes + pronouncing.rhymes(word)))\n",
    "    # Remove unwanted words\n",
    "    rhymes = list(filter(lambda w: filter_rhyme(w), rhymes))\n",
    "    # If there aren't any rhymes, return the current word\n",
    "    if len(rhymes) == 0:\n",
    "        return word\n",
    "    else:\n",
    "        # Make sure k is smaller than total number of rhymes available\n",
    "        k = min(RHYME_K, len(rhymes))\n",
    "        # Get word frequency of rhymes\n",
    "        probs = list(map(lambda r: word_frequency(r, \"en\"), rhymes))\n",
    "        probs_tensor = torch.tensor(probs)\n",
    "        # Get top k\n",
    "        vals, idxs = torch.topk(probs_tensor, k)\n",
    "        if context is not None and len(context) > 0:\n",
    "            candidates = [rhymes[x] for x in idxs.tolist()]\n",
    "            pick = pick_similar(context, candidates, history)\n",
    "            return pick\n",
    "        else:\n",
    "            # Pick uniformly\n",
    "            r = random.randint(0, k - 1)\n",
    "            return rhymes[idxs[r].item()]\n",
    "\n",
    "\n",
    "### Pick rhyme, redirects to pick_perfect_rhyme or pick_near_rhyme\n",
    "def pick_rhyme(word, perfect=True, context=None, history=[]):\n",
    "    if perfect:\n",
    "        return pick_perfect_rhyme(word, context=context, history=history)\n",
    "    else:\n",
    "        return pick_near_rhyme(word, context=context, history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "\n",
    "def interactive_pick_line(lines):\n",
    "    result = None\n",
    "    print(\"GENERATED CANDIDATES:\")\n",
    "    for i, line in enumerate(lines):\n",
    "        print(\"[\" + str(i) + \"] \" + line)\n",
    "    inp = input(\"CHOOSE BY NUMBER (0-\" + str(len(lines) - 1) + \") OR WRITE YOUR OWN: \")\n",
    "    try:\n",
    "        idx = int(inp)\n",
    "        result = lines[idx]\n",
    "    except ValueError:\n",
    "        result = inp\n",
    "    return result, INF\n",
    "\n",
    "\n",
    "### Score a sentence, lower is better (cross entropy)\n",
    "\n",
    "def score_sentence(sentence):\n",
    "    # encode sentence\n",
    "    prompt = gpt2_tokenizer.encode(sentence)\n",
    "    # Set up x and y as shifted input\n",
    "    x = torch.tensor([prompt[:-1]])\n",
    "    y = torch.tensor(prompt[1:])\n",
    "    if CUDA_AVAILABLE:\n",
    "        x = x.to(\"cuda\")\n",
    "        y = y.to(\"cuda\")\n",
    "    # prep_gpt()\n",
    "    # Measure the logits for loss\n",
    "    output, new_past = gpt2_model(x, past_key_values=None)\n",
    "    score = LOSS(output[0], y)\n",
    "    return score\n",
    "\n",
    "\n",
    "### Pick the best line. Run them all through the scoring function and pick the smallest\n",
    "def pick_best_line(lines, context, history=[], interactive=False):\n",
    "    if interactive:\n",
    "        return interactive_pick_line(lines)\n",
    "    else:\n",
    "        # Remove duplicates\n",
    "        modified_history = list(\n",
    "            map(\n",
    "                lambda s: remove_punctuation(s).encode(\"ascii\", \"ignore\").lower(),\n",
    "                history,\n",
    "            )\n",
    "        )\n",
    "        filtered_lines = list(\n",
    "            filter(\n",
    "                lambda s: remove_punctuation(s).encode(\"ascii\", \"ignore\").lower()\n",
    "                not in modified_history,\n",
    "                lines,\n",
    "            )\n",
    "        )\n",
    "        lines = filtered_lines if len(filtered_lines) > 0 else lines\n",
    "        # Score sentences\n",
    "        scores = list(map(lambda l: score_sentence(merge_lines(context, l)), lines))\n",
    "        scores_tensor = torch.tensor(scores, dtype=torch.float)\n",
    "        # for i, line in enumerate(lines):\n",
    "        #  print(\"SCORE\", scores[i].item(), line)\n",
    "        # Get smallest\n",
    "        if len(lines) == 1:\n",
    "            return lines[0], scores[0].item()\n",
    "        elif GREEDY_PICK_LINE:\n",
    "            vals, idxs = torch.topk(scores_tensor, 1, largest=False)\n",
    "            idx = idxs[0].item()\n",
    "            return lines[idx], vals[0].item()\n",
    "        else:\n",
    "            try:\n",
    "                shifted = scores_tensor - min(scores_tensor)\n",
    "                flipped = (max(shifted) - shifted).div(max(shifted))\n",
    "                exped = flipped.div(PICK_LINE_TEMPERATURE).exp()\n",
    "                idxs = torch.multinomial(exped, 1)\n",
    "                idx = idxs[0].item()\n",
    "            except:\n",
    "                # Probably a div by zero\n",
    "                # Usually caused when all the sentences are the same and thus have the same scores\n",
    "                # Which means shifted is a tensor of 0s\n",
    "                idx = 0\n",
    "            print(\"PICK\", lines[idx])\n",
    "            return lines[idx], scores[idx].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_IDX = 6  # MASK is token id 6\n",
    "PERIOD_IDX = 9  # Period is token id 9\n",
    "# Things I don't want generated\n",
    "XLNET_NO_TOKENS = [\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    10,\n",
    "    11,\n",
    "    12,\n",
    "    13,\n",
    "    14,\n",
    "    15,\n",
    "    16,\n",
    "    2055,\n",
    "    6490,\n",
    "    26,\n",
    "    97,\n",
    "    167,\n",
    "    225,\n",
    "    4145,\n",
    "    3158,\n",
    "    17115,\n",
    "    22891,\n",
    "    17666,\n",
    "    4538,\n",
    "    1926,\n",
    "    22788,\n",
    "    2780,\n",
    "    19348,\n",
    "    16011,\n",
    "] + XLNET_NUMBER_TOKENS\n",
    "NINF = -float(\"Inf\")  # Negative infinity\n",
    "INF = float(\"Inf\")  # Positive infinity\n",
    "\n",
    "\n",
    "### Given a prompt, with one or more '<mask>' in it, fill the masks in with XLNET\n",
    "### Can go forward or backward. Backward seems to work better?\n",
    "\n",
    "def fill_line(prompt, backward=False):\n",
    "    generated_tokens = []\n",
    "    # Convert prompt into tokens\n",
    "    input_ids = torch.tensor(\n",
    "        xlnet_tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    ).unsqueeze(0)\n",
    "    # mask out the places we want to predict\n",
    "    perm_mask = torch.zeros(\n",
    "        (1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float\n",
    "    )\n",
    "    masked = input_ids == MASK_IDX\n",
    "    perm_mask = perm_mask + masked\n",
    "    # The places we want to predict are...\n",
    "    predicts = torch.nonzero(masked[0]).tolist()\n",
    "    if backward:\n",
    "        predicts = list(reversed(predicts))\n",
    "    # Set up a diagonal where we want to predict, dim=0 is batch, dim=1 is each prediction\n",
    "    target_mapping = torch.zeros(\n",
    "        (1, len(predicts), input_ids.shape[1]), dtype=torch.float\n",
    "    )\n",
    "    for n, p in enumerate(predicts):\n",
    "        target_mapping[0][n][p] = 1.0\n",
    "    # prep_xlnet()\n",
    "    if CUDA_AVAILABLE:\n",
    "        input_ids = input_ids.to(\"cuda\")\n",
    "        perm_mask = perm_mask.to(\"cuda\")\n",
    "        target_mapping = target_mapping.to(\"cuda\")\n",
    "\n",
    "    # Fill one mask at a time until there are no places to fill (predicts is empty)\n",
    "    while len(predicts) > 0:\n",
    "        # Predict everything, but ignore all but the first prediction\n",
    "        outputs = xlnet_model(input_ids, perm_mask=perm_mask, target_mapping=target_mapping)\n",
    "        next_token_logits = outputs[\n",
    "            0\n",
    "        ]  # Output has shape [target_mapping.size(0), target_mapping.size(1), config.vocab_size]\n",
    "        # Filter to top-k\n",
    "        logits = top_k_top_p_filtering(next_token_logits[0][0], top_k=SAMPLE_K)\n",
    "        # Sample from top-k\n",
    "        samples = torch.multinomial(F.softmax(logits), SAMPLE_K)\n",
    "        # Make sure we didn't predict a repetition and not in NO_TOKENS\n",
    "        pos = torch.nonzero(target_mapping[0][0]).item()\n",
    "        previous_token = input_ids[0][pos - 1].item()\n",
    "        next_token = input_ids[0][pos + 1].item()\n",
    "        token = None\n",
    "        for i in range(SAMPLE_K):\n",
    "            tok = samples[i].item()\n",
    "            if (\n",
    "                tok != previous_token\n",
    "                and tok != next_token\n",
    "                and tok not in XLNET_NO_TOKENS\n",
    "            ):\n",
    "                # Avoid ALL punctuation\n",
    "                if not is_punctuation(xlnet_tokenizer.decode(tok)):\n",
    "                    # avoid repeat tokens\n",
    "                    word = xlnet_tokenizer.decode(tok)\n",
    "                    if (\n",
    "                        word.lower()\n",
    "                        not in xlnet_tokenizer.decode(generated_tokens).lower()\n",
    "                    ):\n",
    "                        # avoid ending with weird words\n",
    "                        # if word.lower() in END_NO_WORDS:\n",
    "                        #  print('--', word.lower(), len(predicts))\n",
    "                        if word.lower() not in END_NO_WORDS or len(predicts) > 1:\n",
    "                            token = tok\n",
    "                            generated_tokens.append(tok)\n",
    "                            break\n",
    "        if token is None:\n",
    "            token = samples[0].item()\n",
    "            generated_tokens.append(token)\n",
    "        # insert the token into the input\n",
    "        input_ids[0][pos] = token\n",
    "        # print(XLNET_TOKENIZER.decode(input_ids[0]))\n",
    "        # Mask out everything that needs to be masked\n",
    "        perm_mask = torch.zeros(\n",
    "            (1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float\n",
    "        )\n",
    "        perm_mask = perm_mask.to(\"cuda\")\n",
    "        masked = input_ids == 6\n",
    "        perm_mask = perm_mask + masked\n",
    "        # Update predicts, should be one less\n",
    "        predicts = torch.nonzero(masked[0]).tolist()\n",
    "        if backward:\n",
    "            predicts = list(reversed(predicts))\n",
    "        # Set up a diagonal where we want to predict, dim=0 is batch, dim=1 is each prediction\n",
    "        target_mapping = torch.zeros(\n",
    "            (1, len(predicts), input_ids.shape[1]), dtype=torch.float\n",
    "        )\n",
    "        for n, p in enumerate(predicts):\n",
    "            target_mapping[0][n][p] = 1.0\n",
    "        target_mapping = target_mapping.to(\"cuda\")\n",
    "    return xlnet_tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rhyme_line(rhyme, context, target_syllables, terminate_line=True):\n",
    "  good_tries = [] # runs with the exact number of syllables\n",
    "  bad_tries = {}  # Runs with fewer syllables (dict is num_syllables: list of lines)\n",
    "  # i is number of masks\n",
    "  # j is number of tries\n",
    "  for i in range(int(target_syllables*1.5)):\n",
    "    for j in range(NUM_TRIES):\n",
    "      ## Even tries have a period added at the end of the previous context\n",
    "      #if j % 2 == 0 and len(context) > 0 and context[-1] not in PUNCTUATION and not no_terminate_previous:\n",
    "      #  context_copy = context[:] + PERIOD\n",
    "      #else:\n",
    "      context_copy = context[:] + BLANK\n",
    "      # This fixes things up\n",
    "      context_copy = xlnet_tokenizer.decode(xlnet_tokenizer.encode(context_copy, add_special_tokens=False))\n",
    "      # Make masks\n",
    "      prompt = context_copy + BLANK + BLANK.join(['<mask>']*(i+1)) + BLANK + rhyme\n",
    "      if terminate_line or j % 2 == 1:\n",
    "        prompt = prompt + PERIOD\n",
    "      # Fill masks\n",
    "      filled_line = fill_line(prompt, backward=True)\n",
    "      # Figure out how many syllables we added\n",
    "      candidate = remove_prefix(filled_line, context_copy).strip() # the newly added line\n",
    "      line_syllable_count = get_syllables_for_line(candidate) # Number of syllables in newly added line\n",
    "      # Did we get a good run?\n",
    "      if line_syllable_count == target_syllables:\n",
    "        good_tries.append(candidate)\n",
    "        print(\"CANDIDATE\", candidate)\n",
    "      elif line_syllable_count < target_syllables:\n",
    "        # Bad tries are those that are too short. Store in dict by length\n",
    "        if line_syllable_count not in bad_tries:\n",
    "          bad_tries[line_syllable_count] = []\n",
    "        bad_tries[line_syllable_count].append(candidate)\n",
    "  return good_tries, bad_tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_NO_TOKENS = [\n",
    "    59,\n",
    "    50256,\n",
    "    1,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    12,\n",
    "    14,\n",
    "    26,\n",
    "    58,\n",
    "    59,\n",
    "    60,\n",
    "    62,\n",
    "    90,\n",
    "    92,\n",
    "    2503,\n",
    "    3,\n",
    "    1906,\n",
    "    14988,\n",
    "    26391,\n",
    "    4023,\n",
    "    338,\n",
    "    40578,\n",
    "    14231,\n",
    "    14036,\n",
    "    15466,\n",
    "    525,\n",
    "] + GPT_NUMBER_TOKENS\n",
    "\n",
    "\n",
    "\n",
    "def generate_non_rhyme_line(context, target_syllables):\n",
    "    generated_tokens = []  # Tokens generated along the way\n",
    "    good_tries = []  # results with the correct number of syllables\n",
    "    past_syllables = get_syllables_for_line(\n",
    "        context\n",
    "    )  # How many syllables in the context\n",
    "    # prep_gpt()\n",
    "    # j is number of tries\n",
    "    for j in range(NUM_TRIES):\n",
    "        new_syllables = 0  # How many new syllables were produced\n",
    "        # Odd tries add a period to the context\n",
    "        # if j % 2 == 0 and len(context) and context[-1] not in PUNCTUATION and not no_terminate_previous:\n",
    "        #  context_copy = context[:] + PERIOD\n",
    "        # else:\n",
    "        context_copy = context[:] + BLANK\n",
    "        # Encode the context\n",
    "        generated = gpt2_tokenizer.encode(context_copy)  # Used to collect up tokens\n",
    "        prompt = torch.tensor([generated])  # context put into the right shape\n",
    "        prompt = prompt.to(\"cuda\") if CUDA_AVAILABLE else prompt\n",
    "        past = None  # Initially we don't have any history\n",
    "        # Generate until we get enough syllables\n",
    "        previous_token = generated[-1] if len(generated) > 0 else None\n",
    "        count = 0\n",
    "        while (\n",
    "            new_syllables < target_syllables and count < 1000\n",
    "        ):  # break loop if too many iterations\n",
    "            # Generate\n",
    "            output, new_past = gpt2_model(prompt, past_key_values=past)\n",
    "            # Top k filter: there are k real numbers and the rest are -inf\n",
    "            logits = top_k_top_p_filtering(output[0][0], top_k=SAMPLE_K)\n",
    "            tokens = torch.multinomial(F.softmax(logits), SAMPLE_K)\n",
    "            # Pick the first one from the top k that doesn't produce too many syllables\n",
    "            for tok in tokens.tolist():\n",
    "                # How many syllables do we have total?\n",
    "                line_syllables = get_syllables_for_line(\n",
    "                    gpt2_tokenizer.decode(generated + [tok])\n",
    "                )\n",
    "                # Have we gone over? Or generated a NO_TOKEN?\n",
    "                if (\n",
    "                    line_syllables <= target_syllables + past_syllables\n",
    "                    and tok not in GPT_NO_TOKENS\n",
    "                ):\n",
    "                    # We are good\n",
    "                    word = gpt2_tokenizer.decode(tok)  # The new word\n",
    "                    # Don't allow ANY punctuation\n",
    "                    if not is_punctuation(word):\n",
    "                        if (\n",
    "                            word.lower()\n",
    "                            not in gpt2_tokenizer.decode(generated_tokens).lower()\n",
    "                        ):\n",
    "                            generated_tokens.append(tok)\n",
    "                            # Add new word to generated\n",
    "                            generated.append(tok)\n",
    "                            # Prep for the next run\n",
    "                            prompt = torch.tensor([tok]).unsqueeze(0)\n",
    "                            prompt = prompt.to(\"cuda\")\n",
    "                            past = new_past\n",
    "                            new_syllables = line_syllables - past_syllables\n",
    "                            break\n",
    "            count = count + 1\n",
    "        candidate = remove_prefix(gpt2_tokenizer.decode(generated), context).strip()\n",
    "        print(\"CANDIDATE\", candidate)\n",
    "        good_tries.append(candidate)\n",
    "    return good_tries, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_terminal_non_rhyme_line(context, target_syllables):\n",
    "    good_tries = []  # runs with the exact number of syllables\n",
    "    bad_tries = {}  # Runs with fewer syllables (dict is num_syllables: list of lines)\n",
    "    # i is number of masks\n",
    "    # j is number of tries\n",
    "    for i in range(int(target_syllables * 1.5)):\n",
    "        for j in range(NUM_TRIES):\n",
    "            # Even tries have a period added at the end of the previous context\n",
    "            # if j % 2 == 0 and len(context) > 0 and context[-1] not in PUNCTUATION and not no_terminate_previous:\n",
    "            #  context_copy = context[:] + PERIOD\n",
    "            # else:\n",
    "            context_copy = context[:] + BLANK\n",
    "            # This fixes things up\n",
    "            context_copy = xlnet_tokenizer.decode(\n",
    "                xlnet_tokenizer.encode(context_copy, add_special_tokens=False)\n",
    "            )\n",
    "            # Make masks\n",
    "            prompt = (\n",
    "                context_copy + BLANK + BLANK.join([\"<mask>\"] * (i + 1)) + PERIOD\n",
    "            )  # Different from generate_rhyme_line\n",
    "            # Fill masks\n",
    "            filled_line = fill_line(\n",
    "                prompt, backward=False\n",
    "            )  # Forward instead of backward\n",
    "            # Figure out how many syllables we added\n",
    "            candidate = remove_prefix(\n",
    "                filled_line, context_copy\n",
    "            ).strip()  # the newly added line\n",
    "            line_syllable_count = get_syllables_for_line(\n",
    "                candidate\n",
    "            )  # Number of syllables in newly added line\n",
    "            # Did we get a good run?\n",
    "            if line_syllable_count == target_syllables:\n",
    "                good_tries.append(candidate)\n",
    "                print(\"CANDIDATE\", candidate)\n",
    "            elif line_syllable_count < target_syllables:\n",
    "                # Bad tries are those that are too short. Store in dict by length\n",
    "                if line_syllable_count not in bad_tries:\n",
    "                    bad_tries[line_syllable_count] = []\n",
    "                bad_tries[line_syllable_count].append(candidate)\n",
    "    return good_tries, bad_tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "def run(context, scheme, rhyme_dict, use_near_rhymes = False, post = None, \n",
    "        recontextualize = False, interactive = False):\n",
    "  ### SETUP #####################################\n",
    "  lines = []    # Store the lyrics lines\n",
    "  segments = [] # Store each segment separately\n",
    "  # Set up the context\n",
    "  context = context[:].strip()\n",
    "  original_context = context[:]\n",
    "  # Set up rhyme history\n",
    "  rhyme_history = [] # The history of words used for rhymes\n",
    "  # original context shouldn't have punctuation at the end, but the first prompt to the neural net should\n",
    "  if len(context) >0 and context[-1] not in PUNCTUATION:\n",
    "    context = context + PERIOD\n",
    "  if len(original_context) > 0 and original_context[-1] in PUNCTUATION:\n",
    "    original_context = original_context[:-1]\n",
    "  # copy the rhyme_dict because we will be adding to it\n",
    "  rhyme_dict = copy.deepcopy(rhyme_dict)\n",
    "  ### ITERATE THROUGH SCHEME #####################\n",
    "  # An entry can be tuples or lists of tuples. \n",
    "  # Easiest thing is to nest tuples into lists and treat everything the same\n",
    "  for n, entry in enumerate(scheme):\n",
    "    ### RECONTEXTUALIZE ##########################\n",
    "    # Insert the original context into the history/context at sentence breaks\n",
    "    if n > 0 and recontextualize:\n",
    "      last_period = context.rfind(PERIOD)\n",
    "      last_contextualization = context.rfind(original_context)\n",
    "      if last_period >= 0 and last_contextualization >= 0 and last_contextualization + len(original_context) - 1 != last_period - 1:\n",
    "        context = merge_lines(merge_lines(context[:last_period+1], original_context, force_break=True), context[last_period+1:], force_break=True)\n",
    "    ### ITERATE THROUGH LINE SPEC #################\n",
    "    current_line = []   # The line currently being worked on. May be made of several segments\n",
    "    # if line is a single segment, nest it\n",
    "    if isinstance(entry, tuple):\n",
    "      entry = [entry]\n",
    "    # A line has 1 or more tuples of the form (target_syllables, rhyme_index)\n",
    "    for segment_num, segment in enumerate(entry):\n",
    "      is_end_segment = (segment_num == len(entry) - 1)\n",
    "      target_syllables = segment[0]\n",
    "      rhyme_idx = segment[1]\n",
    "      cmd = None\n",
    "      goods = []    # lines with the right number of syllables\n",
    "      shorts = {}   # lines with too few syllables\n",
    "      new_context = None # The complete lyrics after a new line is added\n",
    "      new_syllables = 0 # The number of new syllables added to lyrics\n",
    "      terminate_segment = False\n",
    "      ### PARSE SPECIAL COMMANDS ##################\n",
    "      # We have commands to parse\n",
    "      if len(segment) > 2:\n",
    "        cmd = segment[2]\n",
    "        terminate_segment = (cmd == ':end')\n",
    "      print(\"LINE\", n, \"SEGMENT\", segment_num, '(end)' if is_end_segment else '', \"TARGET SYLLABLES\", target_syllables, \"RHYME INDEX\", rhyme_idx, \"COMMAND\", cmd)\n",
    "      # Check if we are filling in a partial line (when there is a rhyme or when there is a given verbatim string)\n",
    "      if isinstance(rhyme_idx, str) or rhyme_idx in rhyme_dict:\n",
    "        ### USE RHYME INDEX ########################\n",
    "        # We are filling a line\n",
    "        end_targets = [] # The line should end in this word (or words)\n",
    "        ### RHYME INDEX IS A STRING ####\n",
    "        if isinstance(rhyme_idx, str):\n",
    "          # Use a verbatim string\n",
    "          end_targets = [rhyme_idx] # rhyme_idx is actually a string\n",
    "          # If target_syllables < 0 then set it to the exact number of syllables in the rhyme_idx string\n",
    "          if target_syllables < 0:\n",
    "            target_syllables = get_syllables_for_line(rhyme_idx)\n",
    "        ### PICK A RHYME WORD ####\n",
    "        else:\n",
    "          # Get some rhyming words\n",
    "          # but first fix the dictionary if there is a single word instead of a list\n",
    "          if not isinstance(rhyme_dict[rhyme_idx], list) and not isinstance(rhyme_dict[rhyme_idx], tuple):\n",
    "            rhyme_dict[rhyme_idx] = [rhyme_dict[rhyme_idx]]\n",
    "          # Now get some words\n",
    "          if rhyme_idx not in rhyme_dict:\n",
    "            pdb.set_trace()\n",
    "          end_targets = [pick_rhyme(w, perfect=not use_near_rhymes, context=context, history=rhyme_history) for w in rhyme_dict[rhyme_idx]]\n",
    "        # There could be more than one possible rhyme target\n",
    "        ### GENERATE #####\n",
    "        for end_target in end_targets:\n",
    "          print(\"RHYME TARGET\", end_target)\n",
    "          # Check to see if the end_target already fills up all of our syllable length\n",
    "          end_target_syllables = get_syllables_for_line(end_target)\n",
    "          if end_target_syllables < target_syllables:\n",
    "            # Generate new lines\n",
    "            meet_target_syllables, too_short = generate_rhyme_line(end_target, context, target_syllables, terminate_line=terminate_segment)\n",
    "            goods = goods + meet_target_syllables\n",
    "            shorts = merge_dicts(shorts, too_short)\n",
    "          else:\n",
    "            # Just copy the end target because that is all the syllables we need\n",
    "            goods.append(end_target)\n",
    "      else:\n",
    "        ### NON-RHYME SEGMENT ###############################\n",
    "        # We are generating a new line unconstrained\n",
    "        # Generate new line\n",
    "        if terminate_segment:\n",
    "          # We've determined this segment must be terminal.\n",
    "          match_target_syllables1, shorts = generate_terminal_non_rhyme_line(context, target_syllables)\n",
    "          goods = match_target_syllables1\n",
    "        else:\n",
    "          # Segment does not need to be terminal\n",
    "          match_target_syllables1, _ = generate_non_rhyme_line(context, target_syllables)\n",
    "          match_target_syllables2 =  []\n",
    "          if is_end_segment:\n",
    "            match_target_syllables2, shorts = generate_terminal_non_rhyme_line(context, target_syllables)\n",
    "          goods = match_target_syllables1 + match_target_syllables2\n",
    "      ### PICK BEST CANDIDATE ############################################\n",
    "      results = []\n",
    "      if len(goods) > 0:\n",
    "        results = goods\n",
    "      else:\n",
    "        longest_key = max(list(shorts.keys()))\n",
    "        results = shorts[longest_key]\n",
    "      best_continuation, score = pick_best_line(results, context, history=segments, interactive=interactive)\n",
    "      new_syllables = get_syllables_for_line(best_continuation)\n",
    "      ### UPDATE RHYME DICTIONARY AND RHYME HISTORY ####################################\n",
    "      # If we are using near rhymes, store the near rhyme as possible target for future lines\n",
    "      if not isinstance(rhyme_idx, str) and rhyme_idx >=0:\n",
    "        # get end word\n",
    "        continuation = ''.join(list(filter(lambda c: c in STR_LETTERS or c == BLANK, best_continuation)))\n",
    "        split_continuation = continuation.split(BLANK)\n",
    "        end_word = split_continuation[-1]\n",
    "        if end_word[-1] in PUNCTUATION:\n",
    "          end_word = end_word[:-1]\n",
    "        # Make a new entry in rhyme_dict\n",
    "        if (rhyme_idx not in rhyme_dict) or (rhyme_idx in rhyme_dict and use_near_rhymes):\n",
    "          if rhyme_idx not in rhyme_dict:\n",
    "            rhyme_dict[rhyme_idx] = []\n",
    "          rhyme_dict[rhyme_idx].append(end_word)\n",
    "        # Add to rhyme history\n",
    "        rhyme_history.append(end_word)\n",
    "      ### DO SOME FIXING #################################################\n",
    "      # Fill in if we don't have enough syllables\n",
    "      if new_syllables < target_syllables:\n",
    "        rest = add_filler(best_continuation, target_syllables - new_syllables, 0)\n",
    "      ### SET UP CONTEXT FOR NEXT ITERATION ##########################\n",
    "      context = merge_lines(context, best_continuation)\n",
    "      print('CONTEXT', context)\n",
    "      current_line.append(best_continuation)\n",
    "      segments.append(best_continuation)\n",
    "      # get ready for the next iteration\n",
    "      context = crop_line(context)\n",
    "      previous_is_end_segment = is_end_segment\n",
    "    ### DONE WITH LINE #################################################\n",
    "    # put the current line together\n",
    "    lines.append(BLANK.join(fix_final_lines_punctuation(current_line)))\n",
    "  ### DONE WITH SPEC ###################################################\n",
    "  #lines = fix_final_lines_punctuation(lines)\n",
    "  lines = post_process_lines(lines, post)\n",
    "  lines = fix_final_lines_capitalization(lines)\n",
    "  return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scheme(lines, use_near_rhymes = True):\n",
    "  syllables = []\n",
    "  ends = []\n",
    "  rhyme_lines = {}\n",
    "  # Compute syllables per line\n",
    "  for line in lines:\n",
    "    line = line.strip()\n",
    "    num_syl = get_syllables_for_line(line)\n",
    "    syllables.append(num_syl)\n",
    "    ends.append(line[-1] == '.')\n",
    "  # Figure out which lines rhyme, piecewise\n",
    "  for i, line1 in enumerate(lines):\n",
    "    line1 = line1.strip()\n",
    "    words1 = line1.split()\n",
    "    last1 = words1[-1]\n",
    "    for j, line2 in enumerate(lines):\n",
    "      if i != j:\n",
    "        line2 = line2.strip()\n",
    "        words2 = line2.split()\n",
    "        last2 = words2[-1]\n",
    "        if perfect_rhyme(last1, last2) or (use_near_rhymes and near_rhyme(last1, last2)):\n",
    "          if i not in rhyme_lines:\n",
    "            rhyme_lines[i] = []\n",
    "          if j not in rhyme_lines:\n",
    "            rhyme_lines[j] = []\n",
    "          if j not in rhyme_lines[i]:\n",
    "            rhyme_lines[i].append(j)\n",
    "          if i not in rhyme_lines[j]:\n",
    "            rhyme_lines[j].append(i)\n",
    "  # Gather up all rhyming lines\n",
    "  for l1 in list(rhyme_lines.keys()):\n",
    "    for l2 in rhyme_lines[l1]:\n",
    "      for l3 in list(rhyme_lines[l2]):\n",
    "        if l3 not in rhyme_lines[l1]:\n",
    "          rhyme_lines[l1].append(l3)\n",
    "  # reduce to unique sets\n",
    "  rhyme_sets = []\n",
    "  for l in list(rhyme_lines.values()):\n",
    "    rhyme_set = set(l)\n",
    "    if rhyme_set not in rhyme_sets:\n",
    "      rhyme_sets.append(rhyme_set) \n",
    "  # Assign rhyme indexes to lines\n",
    "  rhyme_idxs = {}\n",
    "  for n, s in enumerate(rhyme_sets):\n",
    "    for l in s:\n",
    "      rhyme_idxs[l] = n\n",
    "  # Build schema\n",
    "  schema = []\n",
    "  for n in range(len(lines)):\n",
    "    segment = None\n",
    "    syl_num = syllables[n]\n",
    "    rhyme_idx = rhyme_idxs[n] if n in rhyme_idxs else -1\n",
    "    if ends[n]:\n",
    "      segment = (syl_num, rhyme_idx, ':end')\n",
    "    else:\n",
    "      segment = (syl_num, rhyme_idx)\n",
    "    schema.append(segment)\n",
    "  return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhyme_dict = {}   # Rhyming lines are indicated by number. What word should certain lines rhyme with?\n",
    "post = {}         # Post-processing scheme\n",
    "\n",
    "# BEAT IT, MICHAEL JACKSON\n",
    "scheme = [\n",
    "#They told him don't you ever come around here\n",
    "          (11, 1), #0\n",
    "#Don't want to see your face, you better disappear\n",
    "          [(6, -1), (6, 1)], #1\n",
    "#The fire's in their eyes and their words are really clear\n",
    "          [(5, -1), (7, 1)], #2\n",
    "#So beat it, just beat it\n",
    "          (3, 2, ':end'), #3\n",
    "#You better run, you better do what you can\n",
    "          (11, 3), #4\n",
    "#Don't want to see no blood, don't be a macho man\n",
    "          [(6, -1), (6, 3)], #5\n",
    "#You want to be tough, better do what you can\n",
    "          [(5, -1), (6, 3)], #6\n",
    "#So beat it, but you want to be bad\n",
    "          [(3, 2), (6, -1)], #7\n",
    "#Just beat it, beat it, beat it, beat it\n",
    "          (3, 2, ':end'), #8\n",
    "#No one wants to be defeated\n",
    "          (8, 2), #9\n",
    "#Showin' how funky and strong is your fight\n",
    "          (10, 4), #10\n",
    "#It doesn't matter who's wrong or right\n",
    "          (9, 4), #11\n",
    "#Just beat it, beat it\n",
    "          (3, 2), #12\n",
    "#Just beat it, beat it\n",
    "          (3, 2), #13\n",
    "#Just beat it, beat it\n",
    "          (3, 2), #14\n",
    "#Just beat it, beat it\n",
    "          (3, 2, ':end') #15\n",
    "]\n",
    "#rhyme_dict[1] = ['here']\n",
    "post[3] = (None, ' just {repeat 2}.')\n",
    "post[8] = (None, ' ({repeat 2}), {repeat 2}, ({repeat 2})')\n",
    "post[12] = (None, ' ({repeat 2})')\n",
    "post[13] = (None, ' ({repeat 2})')\n",
    "post[14] = (None, ' ({repeat 2})')\n",
    "post[15] = (None, ' ({repeat 2}), oooooh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Top-k most frequent rhymes\n",
    "RHYME_K = 50                          \n",
    "# for top-k sampling of tokens from language models\n",
    "SAMPLE_K = 40                         \n",
    "# How many times to try a line\n",
    "NUM_TRIES = 6                         \n",
    "### Always pick the best scoring line?\n",
    "GREEDY_PICK_LINE = False\n",
    "### temperature for picking different possible options for lines. Set to 1 to be most permissive. \n",
    "### Set closer to zero to be more conservative and prefer the best scoring line more.\n",
    "PICK_LINE_TEMPERATURE = 0.1\n",
    "### Setting this too high can cause memory problems\n",
    "MAX_CONTEXT_LENGTH = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"explain calculus differentiation rules\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINE 0 SEGMENT 0 (end) TARGET SYLLABLES 11 RHYME INDEX 1 COMMAND None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m# Run the generator\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m RUN_ADVANCED_MODE:\n\u001b[1;32m----> 8\u001b[0m   lines \u001b[39m=\u001b[39m run(context, scheme, rhyme_dict, \n\u001b[0;32m      9\u001b[0m               use_near_rhymes\u001b[39m=\u001b[39;49muse_near_rhymes, \n\u001b[0;32m     10\u001b[0m               post\u001b[39m=\u001b[39;49mpost, \n\u001b[0;32m     11\u001b[0m               recontextualize\u001b[39m=\u001b[39;49mrecontextualize, \n\u001b[0;32m     12\u001b[0m               interactive\u001b[39m=\u001b[39;49minteractive)\n\u001b[0;32m     13\u001b[0m   \u001b[39m# Print the outcome\u001b[39;00m\n\u001b[0;32m     14\u001b[0m   pretty_print(lines)\n",
      "Cell \u001b[1;32mIn[26], line 99\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(context, scheme, rhyme_dict, use_near_rhymes, post, recontextualize, interactive)\u001b[0m\n\u001b[0;32m     96\u001b[0m   goods \u001b[39m=\u001b[39m match_target_syllables1\n\u001b[0;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     98\u001b[0m   \u001b[39m# Segment does not need to be terminal\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m   match_target_syllables1, _ \u001b[39m=\u001b[39m generate_non_rhyme_line(context, target_syllables)\n\u001b[0;32m    100\u001b[0m   match_target_syllables2 \u001b[39m=\u001b[39m  []\n\u001b[0;32m    101\u001b[0m   \u001b[39mif\u001b[39;00m is_end_segment:\n",
      "Cell \u001b[1;32mIn[24], line 62\u001b[0m, in \u001b[0;36mgenerate_non_rhyme_line\u001b[1;34m(context, target_syllables)\u001b[0m\n\u001b[0;32m     60\u001b[0m output, new_past \u001b[39m=\u001b[39m gpt2_model(prompt, past_key_values\u001b[39m=\u001b[39mpast)\n\u001b[0;32m     61\u001b[0m \u001b[39m# Top k filter: there are k real numbers and the rest are -inf\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m logits \u001b[39m=\u001b[39m top_k_top_p_filtering(output[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m], top_k\u001b[39m=\u001b[39;49mSAMPLE_K)\n\u001b[0;32m     63\u001b[0m tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmultinomial(F\u001b[39m.\u001b[39msoftmax(logits), SAMPLE_K)\n\u001b[0;32m     64\u001b[0m \u001b[39m# Pick the first one from the top k that doesn't produce too many syllables\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m, in \u001b[0;36mtop_k_top_p_filtering\u001b[1;34m(logits, top_k, top_p, filter_value)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtop_k_top_p_filtering\u001b[39m(logits, top_k\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, top_p\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, filter_value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mInf\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m      3\u001b[0m     \u001b[39m\"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m        Args:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m            logits: logits distribution shape (vocabulary size)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     \u001b[39massert\u001b[39;00m logits\u001b[39m.\u001b[39;49mdim() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# batch size 1 for now - could be updated for more but the code would be less clear\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     top_k \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(top_k, logits\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))  \u001b[39m# Safety check\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m top_k \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     13\u001b[0m         \u001b[39m# Remove all tokens with a probability less than the last token of the top-k\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "RUN_ADVANCED_MODE = True #@param {type:\"boolean\"}\n",
    "use_near_rhymes = True #@param {type:\"boolean\"}\n",
    "recontextualize = False #@param {type:\"boolean\"}\n",
    "interactive = False #@param {type:\"boolean\"}\n",
    "\n",
    "# Run the generator\n",
    "if RUN_ADVANCED_MODE:\n",
    "  lines = run(context, scheme, rhyme_dict, \n",
    "              use_near_rhymes=use_near_rhymes, \n",
    "              post=post, \n",
    "              recontextualize=recontextualize, \n",
    "              interactive=interactive)\n",
    "  # Print the outcome\n",
    "  pretty_print(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(word):\n",
    "    count = 0\n",
    "    vowels = \"aeiouyAEIOUY\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllable_count(input(\"Put in a word\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
